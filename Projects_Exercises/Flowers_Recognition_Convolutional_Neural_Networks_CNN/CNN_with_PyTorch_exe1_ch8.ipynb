{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_with_PyTorch_exe1_ch8.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUKCIJPPkLDn"
      },
      "source": [
        "# Convolutional Neural Network (CNN) with PyTorch\n",
        "\n",
        "## Exercise 1 of chapter 8 of the book `Deep learning with PyTorch`\n",
        "\n",
        "By [Zahra Taheri](https://github.com/zata213), December 5, 2020"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcnVDjG6h9ev",
        "outputId": "629cc053-45c0-48c0-9ec4-f1edf219003e"
      },
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import collections\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.set_printoptions(edgeitems=2)\n",
        "torch.manual_seed(123)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7eff2c06eb40>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PnM4DHtiJZb"
      },
      "source": [
        "class_names = ['airplane','automobile','bird','cat','deer',\n",
        "               'dog','frog','horse','ship','truck']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23psOtE0iMDT",
        "outputId": "d8f5c5c6-0dcc-45b4-b17a-1aab4076ec04"
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "data_path = '../data-unversioned/p1ch6/'\n",
        "cifar10 = datasets.CIFAR10(\n",
        "    data_path, train=True, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cy1EqQMYiORM",
        "outputId": "968ce287-c97d-454e-8097-3b9843cad14d"
      },
      "source": [
        "cifar10_val = datasets.CIFAR10(\n",
        "    data_path, train=False, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKDV6dPFjusx"
      },
      "source": [
        "label_map = {0: 0, 2: 1}\n",
        "class_names = ['airplane', 'bird']\n",
        "cifar2 = [(img, label_map[label])\n",
        "          for img, label in cifar10\n",
        "          if label in [0, 2]]\n",
        "cifar2_val = [(img, label_map[label])\n",
        "              for img, label in cifar10_val\n",
        "              if label in [0, 2]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuEQbFoji4ez"
      },
      "source": [
        "### With kernel_size=3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iy50PndgiRAk"
      },
      "source": [
        "class Net_3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
        "        self.act1 = nn.Tanh()\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
        "        self.act2 = nn.Tanh()\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
        "        self.act3 = nn.Tanh()\n",
        "        self.fc2 = nn.Linear(32, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.pool1(self.act1(self.conv1(x)))\n",
        "        out = self.pool2(self.act2(self.conv2(out)))\n",
        "        out = out.view(-1, 8 * 8 * 8) # <1>\n",
        "        out = self.act3(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMnfeoVPjBsK"
      },
      "source": [
        "### With kernel_size=5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0Q0K4gfjBsL"
      },
      "source": [
        "class Net_5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, padding=1)\n",
        "        self.act1 = nn.Tanh()\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.conv2 = nn.Conv2d(16, 8, kernel_size=5, padding=1)\n",
        "        self.act2 = nn.Tanh()\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.flatten = nn.Flatten() \n",
        "        self.fc1 = nn.Linear(288, 32)\n",
        "        self.act3 = nn.Tanh()\n",
        "        self.fc2 = nn.Linear(32, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.pool1(self.act1(self.conv1(x)))\n",
        "        out = self.pool2(self.act2(self.conv2(out)))\n",
        "        out = self.flatten(out)\n",
        "        out = self.act3(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCXpjPq_igvQ",
        "outputId": "9bff0abf-cdf8-43bd-f39d-8cb3f522ec98"
      },
      "source": [
        "model = Net_3()\n",
        "\n",
        "numel_list = [p.numel() for p in model.parameters()]\n",
        "sum(numel_list), numel_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18090, [432, 16, 1152, 8, 16384, 32, 64, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNAaAXdYnxsx",
        "outputId": "e9d70b1c-df40-42be-b5ad-281d79971738"
      },
      "source": [
        "from torchsummary import summary\n",
        "summary(model, (3,32,32))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 32, 32]             448\n",
            "              Tanh-2           [-1, 16, 32, 32]               0\n",
            "         MaxPool2d-3           [-1, 16, 16, 16]               0\n",
            "            Conv2d-4            [-1, 8, 16, 16]           1,160\n",
            "              Tanh-5            [-1, 8, 16, 16]               0\n",
            "         MaxPool2d-6              [-1, 8, 8, 8]               0\n",
            "            Linear-7                   [-1, 32]          16,416\n",
            "              Tanh-8                   [-1, 32]               0\n",
            "            Linear-9                    [-1, 2]              66\n",
            "================================================================\n",
            "Total params: 18,090\n",
            "Trainable params: 18,090\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.32\n",
            "Params size (MB): 0.07\n",
            "Estimated Total Size (MB): 0.40\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agGii__1jBsL",
        "outputId": "467ebafc-ff81-40ae-8667-94a04e5bdc7b"
      },
      "source": [
        "model = Net_5()\n",
        "\n",
        "numel_list = [p.numel() for p in model.parameters()]\n",
        "sum(numel_list), numel_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13738, [1200, 16, 3200, 8, 9216, 32, 64, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVmnEVG6nJi0",
        "outputId": "3b183c59-b0af-46d1-a737-dcae4a70e89f"
      },
      "source": [
        "summary(model, (3,32,32))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 30, 30]           1,216\n",
            "              Tanh-2           [-1, 16, 30, 30]               0\n",
            "         MaxPool2d-3           [-1, 16, 15, 15]               0\n",
            "            Conv2d-4            [-1, 8, 13, 13]           3,208\n",
            "              Tanh-5            [-1, 8, 13, 13]               0\n",
            "         MaxPool2d-6              [-1, 8, 6, 6]               0\n",
            "           Flatten-7                  [-1, 288]               0\n",
            "            Linear-8                   [-1, 32]           9,248\n",
            "              Tanh-9                   [-1, 32]               0\n",
            "           Linear-10                    [-1, 2]              66\n",
            "================================================================\n",
            "Total params: 13,738\n",
            "Trainable params: 13,738\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.27\n",
            "Params size (MB): 0.05\n",
            "Estimated Total Size (MB): 0.34\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SolqzjphmBY_"
      },
      "source": [
        "#### **a)** If we change kernel_size from 3x3 to 5x5, the number of parameters decreases from 18090 to 13738."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqgEvNfcjJDK"
      },
      "source": [
        "import datetime  # <1>\n",
        "\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    for epoch in range(1, n_epochs + 1):  # <2>\n",
        "        loss_train = 0.0\n",
        "        for imgs, labels in train_loader:  # <3>\n",
        "            \n",
        "            outputs = model(imgs)  # <4>\n",
        "            \n",
        "            loss = loss_fn(outputs, labels)  # <5>\n",
        "\n",
        "            optimizer.zero_grad()  # <6>\n",
        "            \n",
        "            loss.backward()  # <7>\n",
        "            \n",
        "            optimizer.step()  # <8>\n",
        "\n",
        "            loss_train += loss.item()  # <9>\n",
        "\n",
        "        if epoch == 1 or epoch % 10 == 0:\n",
        "            print('{} Epoch {}, Training loss {}'.format(\n",
        "                datetime.datetime.now(), epoch,\n",
        "                loss_train / len(train_loader)))  # <10>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcVYlb_Fjc4Z",
        "outputId": "be1628d4-1ebf-4dd9-a053-54deff5bd2f8"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=True)  # <1>\n",
        "\n",
        "model = Net_3()  #  <2>\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)  #  <3>\n",
        "loss_fn = nn.CrossEntropyLoss()  #  <4>\n",
        "\n",
        "training_loop(  # <5>\n",
        "    n_epochs = 100,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-08 13:07:46.365656 Epoch 1, Training loss 0.6041859838233632\n",
            "2020-12-08 13:08:22.616780 Epoch 10, Training loss 0.35150224815128717\n",
            "2020-12-08 13:09:02.910174 Epoch 20, Training loss 0.29384877319168895\n",
            "2020-12-08 13:09:43.783350 Epoch 30, Training loss 0.2623802735262616\n",
            "2020-12-08 13:10:24.716709 Epoch 40, Training loss 0.23805504752572176\n",
            "2020-12-08 13:11:04.552352 Epoch 50, Training loss 0.2195895376858438\n",
            "2020-12-08 13:11:45.306755 Epoch 60, Training loss 0.2026940283786719\n",
            "2020-12-08 13:12:25.146268 Epoch 70, Training loss 0.18730561691484635\n",
            "2020-12-08 13:13:05.679425 Epoch 80, Training loss 0.17256072951350243\n",
            "2020-12-08 13:13:45.913962 Epoch 90, Training loss 0.15853702300673078\n",
            "2020-12-08 13:14:26.281938 Epoch 100, Training loss 0.1475972858773675\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDp_K1WKjjME",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d9da66d-db77-4043-fcfd-201c5ab92325"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=False)\n",
        "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
        "                                         shuffle=False)\n",
        "\n",
        "def validate(model, train_loader, val_loader):\n",
        "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():  # <1>\n",
        "            for imgs, labels in loader:\n",
        "                outputs = model(imgs)\n",
        "                _, predicted = torch.max(outputs, dim=1) # <2>\n",
        "                total += labels.shape[0]  # <3>\n",
        "                correct += int((predicted == labels).sum())  # <4>\n",
        "\n",
        "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
        "\n",
        "validate(model, train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy train: 0.92\n",
            "Accuracy val: 0.88\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Djvm23eGmkDW",
        "outputId": "84ceb96b-7a6a-4037-e518-e68983f81037"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=True)  # <1>\n",
        "\n",
        "model = Net_5()  #  <2>\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)  #  <3>\n",
        "loss_fn = nn.CrossEntropyLoss()  #  <4>\n",
        "\n",
        "training_loop(  # <5>\n",
        "    n_epochs = 100,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-08 13:14:33.871091 Epoch 1, Training loss 0.562738618843115\n",
            "2020-12-08 13:15:13.116454 Epoch 10, Training loss 0.33893521433802926\n",
            "2020-12-08 13:15:56.595942 Epoch 20, Training loss 0.29237931283416263\n",
            "2020-12-08 13:16:39.950547 Epoch 30, Training loss 0.2623655254104335\n",
            "2020-12-08 13:17:23.196080 Epoch 40, Training loss 0.23606456332145984\n",
            "2020-12-08 13:18:06.726849 Epoch 50, Training loss 0.2113819701276767\n",
            "2020-12-08 13:18:50.745517 Epoch 60, Training loss 0.18575189234154998\n",
            "2020-12-08 13:19:34.780410 Epoch 70, Training loss 0.16641135948004238\n",
            "2020-12-08 13:20:19.031219 Epoch 80, Training loss 0.14494506027668144\n",
            "2020-12-08 13:21:03.396640 Epoch 90, Training loss 0.128674705305202\n",
            "2020-12-08 13:21:47.496057 Epoch 100, Training loss 0.11188445038571479\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-ArjPmcmkDX",
        "outputId": "c7d81d61-5843-43f6-dc3d-02541f94d5d2"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=False)\n",
        "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
        "                                         shuffle=False)\n",
        "\n",
        "def validate(model, train_loader, val_loader):\n",
        "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():  # <1>\n",
        "            for imgs, labels in loader:\n",
        "                outputs = model(imgs)\n",
        "                _, predicted = torch.max(outputs, dim=1) # <2>\n",
        "                total += labels.shape[0]  # <3>\n",
        "                correct += int((predicted == labels).sum())  # <4>\n",
        "\n",
        "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
        "\n",
        "validate(model, train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy train: 0.93\n",
            "Accuracy val: 0.87\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rm8pfxdehHbE"
      },
      "source": [
        "#### **b)** If we change kernel_size from 3x3 to 5x5, the training accuracy increases from 0.92 to 0.93, while the validation accuracy decreases from 0.88 to 0.87. So, the change degrade overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCVrRwrjiuKm"
      },
      "source": [
        "### With kernel_size=(1,3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ov6FYTzciuKo"
      },
      "source": [
        "class Net_13(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=(1,3), padding=1)\n",
        "        self.act1 = nn.Tanh()\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.conv2 = nn.Conv2d(16, 8, kernel_size=(1,3), padding=1)\n",
        "        self.act2 = nn.Tanh()\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.flatten = nn.Flatten() \n",
        "        self.fc1 = nn.Linear(576, 32)\n",
        "        self.act3 = nn.Tanh()\n",
        "        self.fc2 = nn.Linear(32, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.pool1(self.act1(self.conv1(x)))\n",
        "        out = self.pool2(self.act2(self.conv2(out)))\n",
        "        out = self.flatten(out)\n",
        "        out = self.act3(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJjvKci5iuKo",
        "outputId": "991aafb1-d8df-4bec-d5ac-dd36b90d5e1d"
      },
      "source": [
        "model = Net_13()\n",
        "\n",
        "numel_list = [p.numel() for p in model.parameters()]\n",
        "sum(numel_list), numel_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19082, [144, 16, 384, 8, 18432, 32, 64, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPUNQWO6iuKq",
        "outputId": "531c34f8-e66b-49c1-daa9-9cae436d9fc9"
      },
      "source": [
        "from torchsummary import summary\n",
        "summary(model, (3,32,32))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 34, 32]             160\n",
            "              Tanh-2           [-1, 16, 34, 32]               0\n",
            "         MaxPool2d-3           [-1, 16, 17, 16]               0\n",
            "            Conv2d-4            [-1, 8, 19, 16]             392\n",
            "              Tanh-5            [-1, 8, 19, 16]               0\n",
            "         MaxPool2d-6              [-1, 8, 9, 8]               0\n",
            "           Flatten-7                  [-1, 576]               0\n",
            "            Linear-8                   [-1, 32]          18,464\n",
            "              Tanh-9                   [-1, 32]               0\n",
            "           Linear-10                    [-1, 2]              66\n",
            "================================================================\n",
            "Total params: 19,082\n",
            "Trainable params: 19,082\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.35\n",
            "Params size (MB): 0.07\n",
            "Estimated Total Size (MB): 0.43\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YxPVK2Ojixm",
        "outputId": "ee3e68ae-1a62-416b-b3e4-322e98481dd1"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=True)  # <1>\n",
        "\n",
        "model = Net_13()  #  <2>\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)  #  <3>\n",
        "loss_fn = nn.CrossEntropyLoss()  #  <4>\n",
        "\n",
        "training_loop(  # <5>\n",
        "    n_epochs = 100,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-08 13:33:19.786240 Epoch 1, Training loss 0.6084256811886076\n",
            "2020-12-08 13:34:03.993435 Epoch 10, Training loss 0.3547499438000333\n",
            "2020-12-08 13:34:53.428238 Epoch 20, Training loss 0.2999774587761824\n",
            "2020-12-08 13:35:42.983857 Epoch 30, Training loss 0.2708665910799792\n",
            "2020-12-08 13:36:32.526072 Epoch 40, Training loss 0.25456421808072716\n",
            "2020-12-08 13:37:21.956149 Epoch 50, Training loss 0.24369606570263577\n",
            "2020-12-08 13:38:11.135708 Epoch 60, Training loss 0.23021968278535612\n",
            "2020-12-08 13:39:00.157423 Epoch 70, Training loss 0.21708584026356412\n",
            "2020-12-08 13:39:49.545586 Epoch 80, Training loss 0.20586795782207684\n",
            "2020-12-08 13:40:38.146433 Epoch 90, Training loss 0.19146147199497102\n",
            "2020-12-08 13:41:26.572336 Epoch 100, Training loss 0.17867573165589837\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YswFAZl3jixp",
        "outputId": "9667114e-7c5d-4ca3-8a90-58acf0742b8c"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=False)\n",
        "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
        "                                         shuffle=False)\n",
        "\n",
        "def validate(model, train_loader, val_loader):\n",
        "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():  # <1>\n",
        "            for imgs, labels in loader:\n",
        "                outputs = model(imgs)\n",
        "                _, predicted = torch.max(outputs, dim=1) # <2>\n",
        "                total += labels.shape[0]  # <3>\n",
        "                correct += int((predicted == labels).sum())  # <4>\n",
        "\n",
        "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
        "\n",
        "validate(model, train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy train: 0.93\n",
            "Accuracy val: 0.89\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoceYIXkmmMz"
      },
      "source": [
        "#### **d and e)** If we change kernel_size from 3x3 to 1x3, the number of parameters increases from 18090 to 19082. Also, the validation accuracy increases from 0.88 to 0.89. So, the change improve the model performance."
      ]
    }
  ]
}