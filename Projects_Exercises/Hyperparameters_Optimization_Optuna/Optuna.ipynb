{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Optuna.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "180EzUv8Kftq"
      },
      "source": [
        "#  [Optuna](https://optuna.readthedocs.io/en/latest/tutorial/index.html): An Automatic Hyperparameter Optimization Software\n",
        "By [Zahra Taheri](https://github.com/zata213), December 11, 2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjc8P5tsnYM0"
      },
      "source": [
        "## Some good resources and references:\n",
        "- [Optuna tutorial](https://optuna.readthedocs.io/en/latest/tutorial/index.html)\n",
        "- [Hyper-parameter optimization with Optuna](https://towardsdatascience.com/https-medium-com-perlitz-hyper-parameter-optimization-with-optuna-1c32785e7df)\n",
        "- [How We Implement Hyperband in Optuna](https://tech.preferred.jp/en/blog/how-we-implement-hyperband-in-optuna/)\n",
        "- [Using Optuna to Optimize PyTorch Hyperparameters](https://medium.com/pytorch/using-optuna-to-optimize-pytorch-hyperparameters-990607385e36)\n",
        "\n",
        "## Optuna installation:\n",
        "To install this package with conda, run one of the following:\n",
        "- `conda install -c conda-forge optuna`\n",
        "- `conda install -c conda-forge/ label/cf202003 optuna`\n",
        "\n",
        "To install this package with pip, run:\n",
        "- `pip install optuna`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rtc3X45PuUJB"
      },
      "source": [
        "#!pip install optuna"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TnhxlXYcB_E"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(123)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TclON4-nYM6",
        "outputId": "96f4836d-e0d0-4fe1-e319-4cd3d50b65d0"
      },
      "source": [
        "transform = transforms.Compose([transforms.Resize(256),\n",
        "                                transforms.CenterCrop(224),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=[0.4915, 0.4823, 0.4468], std=[0.2470, 0.2435, 0.2616])])\n",
        "\n",
        "trainset = datasets.CIFAR10(root='./data',\n",
        "                                   train=True,\n",
        "                                   transform=transform,\n",
        "                                   download=True)\n",
        "\n",
        "testset = datasets.CIFAR10(root='./data',\n",
        "                                   train=False,\n",
        "                                   transform=transform,\n",
        "                                   download=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-ksOi3RgFOb"
      },
      "source": [
        "class_names = ['airplane','automobile','bird','cat','deer',\r\n",
        "               'dog','frog','horse','ship','truck']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyG-09KcffIL"
      },
      "source": [
        "label_map = {1: 0, 7: 1}\r\n",
        "class_names = ['automobile', 'horse']\r\n",
        "cifar2 = [(img, label_map[label])\r\n",
        "          for img, label in trainset\r\n",
        "          if label in [1, 7]]\r\n",
        "cifar2_val = [(img, label_map[label])\r\n",
        "              for img, label in testset\r\n",
        "              if label in [1, 7]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWB54JKq8IYi"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\r\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUoV8kPQ1QV4"
      },
      "source": [
        "def compute_accuracy(net, data_loader):\r\n",
        "    correct_pred, num_examples = 0, 0\r\n",
        "    with torch.no_grad():\r\n",
        "        for features, targets in data_loader:\r\n",
        "            features = features.to(device)\r\n",
        "            targets = targets.to(device)\r\n",
        "            outputs = net.forward(features)\r\n",
        "            predicted_labels = torch.argmax(outputs, 1)\r\n",
        "            num_examples += targets.size(0)\r\n",
        "            correct_pred += (predicted_labels == targets).sum()\r\n",
        "        return correct_pred.float()/num_examples * 100        \r\n",
        "            \r\n",
        "            \r\n",
        "\r\n",
        "def compute_loss(net, data_loader):\r\n",
        "    curr_loss = 0.\r\n",
        "    with torch.no_grad():\r\n",
        "        for cnt, (features, targets) in enumerate(data_loader):\r\n",
        "            features = features.to(device)\r\n",
        "            targets = targets.to(device)\r\n",
        "            outputs = net.forward(features)\r\n",
        "            loss = criterion(outputs, targets)\r\n",
        "            curr_loss += loss\r\n",
        "        return float(curr_loss)/cnt "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIYTgkLp1QZx"
      },
      "source": [
        "def training(num_epochs, batch_size, optimizer, net):\r\n",
        "  model = net\r\n",
        "  train_loader = torch.utils.data.DataLoader(cifar2, batch_size=batch_size,\r\n",
        "                                          shuffle=True, num_workers=4)\r\n",
        "  test_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=batch_size,\r\n",
        "                                         shuffle=False, num_workers=4)\r\n",
        "  minibatch_cost = []\r\n",
        "  epoch_cost = []\r\n",
        "  for epoch in range(num_epochs):\r\n",
        "    model.train()\r\n",
        "    for batch_idx, (features, targets) in enumerate(train_loader):\r\n",
        "        \r\n",
        "        features = Variable(features.to(device))\r\n",
        "        targets = Variable(targets.to(device))\r\n",
        "            \r\n",
        "        ### FORWARD AND BACK PROP\r\n",
        "        outputs = model(features)\r\n",
        "        \r\n",
        "        cost = criterion(outputs, targets)\r\n",
        "        optimizer.zero_grad()\r\n",
        "        \r\n",
        "        cost.backward()\r\n",
        "        minibatch_cost.append(cost)\r\n",
        "        ### UPDATE MODEL PARAMETERS\r\n",
        "        optimizer.step()\r\n",
        "       \r\n",
        "    model.eval()\r\n",
        "    with torch.no_grad():\r\n",
        "        cost = compute_loss(model, train_loader)\r\n",
        "        epoch_cost.append(cost)\r\n",
        "        \r\n",
        "  model.eval()\r\n",
        "  with torch.no_grad():\r\n",
        "      return compute_accuracy(model, test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dVivXXCoEWE"
      },
      "source": [
        "## Train the model with no hyperparameter optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0O5CqDRltwK"
      },
      "source": [
        "class convnet(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super().__init__()\r\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\r\n",
        "        self.act1 = nn.Tanh()\r\n",
        "        self.pool1 = nn.MaxPool2d(2)\r\n",
        "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\r\n",
        "        self.act2 = nn.Tanh()\r\n",
        "        self.pool2 = nn.MaxPool2d(2)\r\n",
        "        self.flatten = nn.Flatten()\r\n",
        "        self.fc1 = nn.Linear(25088, 32)\r\n",
        "        self.act3 = nn.Tanh()\r\n",
        "        self.fc2 = nn.Linear(32, 2)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        out = self.pool1(self.act1(self.conv1(x)))\r\n",
        "        out = self.pool2(self.act2(self.conv2(out)))\r\n",
        "        out = self.flatten(out)\r\n",
        "        out = self.act3(self.fc1(out))\r\n",
        "        out = self.fc2(out)\r\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdhfdPpPie2q",
        "outputId": "11e21b2f-4532-4b6e-e426-d2d0bdf42139"
      },
      "source": [
        "model = convnet()\r\n",
        "model.to(device)\r\n",
        "summary(model, (3,224,224))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 16, 224, 224]             448\n",
            "              Tanh-2         [-1, 16, 224, 224]               0\n",
            "         MaxPool2d-3         [-1, 16, 112, 112]               0\n",
            "            Conv2d-4          [-1, 8, 112, 112]           1,160\n",
            "              Tanh-5          [-1, 8, 112, 112]               0\n",
            "         MaxPool2d-6            [-1, 8, 56, 56]               0\n",
            "           Flatten-7                [-1, 25088]               0\n",
            "            Linear-8                   [-1, 32]         802,848\n",
            "              Tanh-9                   [-1, 32]               0\n",
            "           Linear-10                    [-1, 2]              66\n",
            "================================================================\n",
            "Total params: 804,522\n",
            "Trainable params: 804,522\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 15.70\n",
            "Params size (MB): 3.07\n",
            "Estimated Total Size (MB): 19.34\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFrmFDCk1QSg"
      },
      "source": [
        "learning_rate = 1e-2\r\n",
        "\r\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CA0wOCNzjQr6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a96ecec8-b942-4461-8d3b-afeb39ffe7f0"
      },
      "source": [
        "batch_size = 8\r\n",
        "n_epochs = 5\r\n",
        "\r\n",
        "training(n_epochs, batch_size, optimizer, model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(90.8000, device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBENGtg3psKH"
      },
      "source": [
        "## Train the model with Optuna (an automatic hyperparameter optimization software)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eolz2rdhmq9C"
      },
      "source": [
        "def objective(trial):\r\n",
        "\r\n",
        "    # generate the model\r\n",
        "    model = ConvNet(trial).to(device)\r\n",
        "\r\n",
        "    # generate the optimizers\r\n",
        "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\r\n",
        "    lr = trial.suggest_loguniform(\"lr\", 1e-4, 1e-1)\r\n",
        "    n_epochs = trial.suggest_int(\"num_epochs\", 3, 5, 7)\r\n",
        "    batch_size = trial.suggest_int(\"batch_size\", 16, 32, 64)\r\n",
        "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\r\n",
        "    \r\n",
        "    accuracy = training(n_epochs, batch_size, optimizer, model)\r\n",
        "\r\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCbyFJSZ1A-6"
      },
      "source": [
        "class ConvNet(nn.Module):\r\n",
        "    def __init__(self, trial):\r\n",
        "        super(ConvNet, self).__init__()\r\n",
        "        self.conv1 = nn.Conv2d(3, trial.suggest_int('num_of_kernel_layer1', 8, 16), kernel_size=3, padding=1)\r\n",
        "        self.act1 = nn.Tanh()\r\n",
        "        self.pool1 = nn.MaxPool2d(2)\r\n",
        "        self.conv2 = nn.Conv2d(trial.suggest_int('num_of_kernel_layer1', 8, 16), trial.suggest_int('num_of_kernel_layer2', 4, 8), kernel_size=3, padding=1)\r\n",
        "        self.act2 = nn.Tanh()\r\n",
        "        self.pool2 = nn.MaxPool2d(2)\r\n",
        "        self.flatten = nn.Flatten()\r\n",
        "        self.fc1 = nn.Linear(trial.suggest_int('num_of_kernel_layer2', 4, 8)*3136, 32)\r\n",
        "        self.act3 = nn.Tanh()\r\n",
        "        self.fc2 = nn.Linear(32, 2)\r\n",
        "    def forward(self, x):\r\n",
        "        out = self.pool1(self.act1(self.conv1(x)))\r\n",
        "        out = self.pool2(self.act2(self.conv2(out)))\r\n",
        "        out = self.flatten(out)\r\n",
        "        out = self.act3(self.fc1(out))\r\n",
        "        out = self.fc2(out)\r\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKlZgdziS3I_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbb87217-be96-4b44-af2b-777dcf552555"
      },
      "source": [
        "import optuna\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=5)\n",
        "\n",
        "pruned_trials = [t for t in study.trials if t.state == optuna.structs.TrialState.PRUNED]\n",
        "complete_trials = [t for t in study.trials if t.state == optuna.structs.TrialState.COMPLETE]\n",
        "\n",
        "print(\"Study statistics: \")\n",
        "print(\"  Number of finished trials: \", len(study.trials))\n",
        "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "print(\"  Number of complete trials: \", len(complete_trials))\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\"  Value: \", trial.value)\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2020-12-11 15:01:48,789]\u001b[0m A new study created in memory with name: no-name-ed7a6eb8-0710-4d8d-ac80-48b86db615b3\u001b[0m\n",
            "\u001b[32m[I 2020-12-11 15:02:48,941]\u001b[0m Trial 0 finished with value: 66.1500015258789 and parameters: {'num_of_kernel_layer1': 12, 'num_of_kernel_layer2': 4, 'optimizer': 'Adam', 'lr': 0.025489786685226803, 'num_epochs': 3, 'batch_size': 16}. Best is trial 0 with value: 66.1500015258789.\u001b[0m\n",
            "\u001b[32m[I 2020-12-11 15:03:48,249]\u001b[0m Trial 1 finished with value: 89.35000610351562 and parameters: {'num_of_kernel_layer1': 11, 'num_of_kernel_layer2': 6, 'optimizer': 'SGD', 'lr': 0.004689450782069958, 'num_epochs': 3, 'batch_size': 16}. Best is trial 1 with value: 89.35000610351562.\u001b[0m\n",
            "\u001b[32m[I 2020-12-11 15:04:44,196]\u001b[0m Trial 2 finished with value: 57.45000076293945 and parameters: {'num_of_kernel_layer1': 8, 'num_of_kernel_layer2': 5, 'optimizer': 'RMSprop', 'lr': 0.09910475013534896, 'num_epochs': 3, 'batch_size': 16}. Best is trial 1 with value: 89.35000610351562.\u001b[0m\n",
            "\u001b[32m[I 2020-12-11 15:05:47,235]\u001b[0m Trial 3 finished with value: 68.85000610351562 and parameters: {'num_of_kernel_layer1': 14, 'num_of_kernel_layer2': 6, 'optimizer': 'Adam', 'lr': 0.003863570950250453, 'num_epochs': 3, 'batch_size': 16}. Best is trial 1 with value: 89.35000610351562.\u001b[0m\n",
            "\u001b[32m[I 2020-12-11 15:06:47,737]\u001b[0m Trial 4 finished with value: 83.80000305175781 and parameters: {'num_of_kernel_layer1': 13, 'num_of_kernel_layer2': 4, 'optimizer': 'SGD', 'lr': 0.0016709175530699107, 'num_epochs': 3, 'batch_size': 16}. Best is trial 1 with value: 89.35000610351562.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Study statistics: \n",
            "  Number of finished trials:  5\n",
            "  Number of pruned trials:  0\n",
            "  Number of complete trials:  5\n",
            "Best trial:\n",
            "  Value:  89.35000610351562\n",
            "  Params: \n",
            "    num_of_kernel_layer1: 11\n",
            "    num_of_kernel_layer2: 6\n",
            "    optimizer: SGD\n",
            "    lr: 0.004689450782069958\n",
            "    num_epochs: 3\n",
            "    batch_size: 16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PkrMtRhN8-4"
      },
      "source": [
        "## Train the model with Optuna using pruning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZYwjsixONtg"
      },
      "source": [
        "def objective(trial):\r\n",
        "\r\n",
        "    # generate the model\r\n",
        "    model = ConvNet(trial).to(device)\r\n",
        "\r\n",
        "    # generate the optimizers\r\n",
        "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\r\n",
        "    lr = trial.suggest_loguniform(\"lr\", 1e-4, 1e-1)\r\n",
        "    n_epochs = trial.suggest_int(\"num_epochs\", 30, 50, 70)\r\n",
        "    batch_size = trial.suggest_int(\"batch_size\", 16, 32, 64)\r\n",
        "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\r\n",
        "    \r\n",
        "    train_loader = torch.utils.data.DataLoader(cifar2, batch_size=batch_size,\r\n",
        "                                          shuffle=True, num_workers=4)\r\n",
        "    test_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=batch_size,\r\n",
        "                                         shuffle=False, num_workers=4)\r\n",
        "    for epoch in range(n_epochs):\r\n",
        "      model.train()\r\n",
        "      for batch_idx, (features, targets) in enumerate(train_loader):\r\n",
        "        features = Variable(features.to(device))\r\n",
        "        targets = Variable(targets.to(device))\r\n",
        "        outputs = model(features)\r\n",
        "        cost = criterion(outputs, targets)\r\n",
        "        optimizer.zero_grad()\r\n",
        "        cost.backward()\r\n",
        "        optimizer.step()\r\n",
        "       \r\n",
        "      model.eval()\r\n",
        "      with torch.no_grad():\r\n",
        "          epoch_acc = compute_accuracy(model, test_loader)\r\n",
        "          trial.report(epoch_acc, epoch)\r\n",
        "          if trial.should_prune():\r\n",
        "              raise optuna.exceptions.TrialPruned()\r\n",
        "        \r\n",
        "    model.eval()\r\n",
        "    with torch.no_grad():\r\n",
        "        acc = compute_accuracy(model, test_loader)\r\n",
        "\r\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qrKh0_0ONt5"
      },
      "source": [
        "class ConvNet(nn.Module):\r\n",
        "    def __init__(self, trial):\r\n",
        "        super(ConvNet, self).__init__()\r\n",
        "        self.conv1 = nn.Conv2d(3, trial.suggest_int('num_of_kernel_layer1', 8, 16), kernel_size=3, padding=1)\r\n",
        "        self.act1 = nn.Tanh()\r\n",
        "        self.pool1 = nn.MaxPool2d(2)\r\n",
        "        self.conv2 = nn.Conv2d(trial.suggest_int('num_of_kernel_layer1', 8, 16), trial.suggest_int('num_of_kernel_layer2', 4, 8), kernel_size=3, padding=1)\r\n",
        "        self.act2 = nn.Tanh()\r\n",
        "        self.pool2 = nn.MaxPool2d(2)\r\n",
        "        self.flatten = nn.Flatten()\r\n",
        "        self.fc1 = nn.Linear(trial.suggest_int('num_of_kernel_layer2', 4, 8)*3136, 32)\r\n",
        "        self.act3 = nn.Tanh()\r\n",
        "        self.fc2 = nn.Linear(32, 2)\r\n",
        "    def forward(self, x):\r\n",
        "        out = self.pool1(self.act1(self.conv1(x)))\r\n",
        "        out = self.pool2(self.act2(self.conv2(out)))\r\n",
        "        out = self.flatten(out)\r\n",
        "        out = self.act3(self.fc1(out))\r\n",
        "        out = self.fc2(out)\r\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvZ8a1xIONt6",
        "outputId": "1348d962-a356-4a46-bd50-7210018c90c5"
      },
      "source": [
        "study = optuna.create_study(direction=\"maximize\", pruner=optuna.pruners.MedianPruner())\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "pruned_trials = [t for t in study.trials if t.state == optuna.structs.TrialState.PRUNED]\n",
        "complete_trials = [t for t in study.trials if t.state == optuna.structs.TrialState.COMPLETE]\n",
        "\n",
        "print(\"Study statistics: \")\n",
        "print(\"  Number of finished trials: \", len(study.trials))\n",
        "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "print(\"  Number of complete trials: \", len(complete_trials))\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\"  Value: \", trial.value)\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2020-12-11 15:06:50,707]\u001b[0m A new study created in memory with name: no-name-9da2bc2d-ffdc-4305-a472-55fded3afce4\u001b[0m\n",
            "\u001b[32m[I 2020-12-11 15:14:28,441]\u001b[0m Trial 0 finished with value: 91.60000610351562 and parameters: {'num_of_kernel_layer1': 12, 'num_of_kernel_layer2': 7, 'optimizer': 'Adam', 'lr': 0.0001637388912054928, 'num_epochs': 30, 'batch_size': 16}. Best is trial 0 with value: 91.60000610351562.\u001b[0m\n",
            "\u001b[32m[I 2020-12-11 15:22:09,201]\u001b[0m Trial 1 finished with value: 88.45000457763672 and parameters: {'num_of_kernel_layer1': 12, 'num_of_kernel_layer2': 8, 'optimizer': 'Adam', 'lr': 0.000764044999937247, 'num_epochs': 30, 'batch_size': 16}. Best is trial 0 with value: 91.60000610351562.\u001b[0m\n",
            "\u001b[32m[I 2020-12-11 15:29:39,520]\u001b[0m Trial 2 finished with value: 88.80001068115234 and parameters: {'num_of_kernel_layer1': 13, 'num_of_kernel_layer2': 4, 'optimizer': 'RMSprop', 'lr': 0.0008140351768055297, 'num_epochs': 30, 'batch_size': 16}. Best is trial 0 with value: 91.60000610351562.\u001b[0m\n",
            "\u001b[32m[I 2020-12-11 15:37:00,390]\u001b[0m Trial 3 finished with value: 80.95000457763672 and parameters: {'num_of_kernel_layer1': 11, 'num_of_kernel_layer2': 8, 'optimizer': 'RMSprop', 'lr': 0.006218609733823696, 'num_epochs': 30, 'batch_size': 16}. Best is trial 0 with value: 91.60000610351562.\u001b[0m\n",
            "\u001b[32m[I 2020-12-11 15:45:16,073]\u001b[0m Trial 4 finished with value: 67.1500015258789 and parameters: {'num_of_kernel_layer1': 16, 'num_of_kernel_layer2': 7, 'optimizer': 'RMSprop', 'lr': 0.0704357397552379, 'num_epochs': 30, 'batch_size': 16}. Best is trial 0 with value: 91.60000610351562.\u001b[0m\n",
            "\u001b[32m[I 2020-12-11 15:45:31,998]\u001b[0m Trial 5 pruned. \u001b[0m\n",
            "\u001b[32m[I 2020-12-11 15:53:29,531]\u001b[0m Trial 6 finished with value: 93.50000762939453 and parameters: {'num_of_kernel_layer1': 14, 'num_of_kernel_layer2': 7, 'optimizer': 'Adam', 'lr': 0.00017348661794897092, 'num_epochs': 30, 'batch_size': 16}. Best is trial 6 with value: 93.50000762939453.\u001b[0m\n",
            "\u001b[32m[I 2020-12-11 15:53:43,540]\u001b[0m Trial 7 pruned. \u001b[0m\n",
            "\u001b[32m[I 2020-12-11 15:53:58,540]\u001b[0m Trial 8 pruned. \u001b[0m\n",
            "\u001b[32m[I 2020-12-11 15:54:14,274]\u001b[0m Trial 9 pruned. \u001b[0m\n",
            "\u001b[32m[I 2020-12-11 15:54:27,596]\u001b[0m Trial 10 pruned. \u001b[0m\n",
            "\u001b[32m[I 2020-12-11 16:02:20,648]\u001b[0m Trial 11 finished with value: 93.20000457763672 and parameters: {'num_of_kernel_layer1': 14, 'num_of_kernel_layer2': 7, 'optimizer': 'Adam', 'lr': 0.00010694088598277277, 'num_epochs': 30, 'batch_size': 16}. Best is trial 6 with value: 93.50000762939453.\u001b[0m\n",
            "\u001b[32m[I 2020-12-11 16:10:40,296]\u001b[0m Trial 12 finished with value: 93.85000610351562 and parameters: {'num_of_kernel_layer1': 16, 'num_of_kernel_layer2': 6, 'optimizer': 'Adam', 'lr': 0.00021732580046107317, 'num_epochs': 30, 'batch_size': 16}. Best is trial 12 with value: 93.85000610351562.\u001b[0m\n",
            "\u001b[32m[I 2020-12-11 16:19:02,641]\u001b[0m Trial 13 finished with value: 92.1500015258789 and parameters: {'num_of_kernel_layer1': 16, 'num_of_kernel_layer2': 6, 'optimizer': 'Adam', 'lr': 0.0002938021332454262, 'num_epochs': 30, 'batch_size': 16}. Best is trial 12 with value: 93.85000610351562.\u001b[0m\n",
            "\u001b[32m[I 2020-12-11 16:19:35,078]\u001b[0m Trial 14 pruned. \u001b[0m\n",
            "\u001b[32m[I 2020-12-11 16:19:51,504]\u001b[0m Trial 15 pruned. \u001b[0m\n",
            "\u001b[32m[I 2020-12-11 16:20:06,780]\u001b[0m Trial 16 pruned. \u001b[0m\n",
            "\u001b[32m[I 2020-12-11 16:20:23,286]\u001b[0m Trial 17 pruned. \u001b[0m\n",
            "\u001b[32m[I 2020-12-11 16:28:01,933]\u001b[0m Trial 18 finished with value: 91.5 and parameters: {'num_of_kernel_layer1': 13, 'num_of_kernel_layer2': 6, 'optimizer': 'Adam', 'lr': 0.00018315384843316674, 'num_epochs': 30, 'batch_size': 16}. Best is trial 12 with value: 93.85000610351562.\u001b[0m\n",
            "\u001b[32m[I 2020-12-11 16:28:18,201]\u001b[0m Trial 19 pruned. \u001b[0m\n",
            "\u001b[32m[I 2020-12-11 16:28:31,821]\u001b[0m Trial 20 pruned. \u001b[0m\n",
            "\u001b[32m[I 2020-12-11 16:28:47,505]\u001b[0m Trial 21 pruned. \u001b[0m\n",
            "\u001b[32m[I 2020-12-11 16:29:02,676]\u001b[0m Trial 22 pruned. \u001b[0m\n",
            "\u001b[32m[I 2020-12-11 16:37:23,554]\u001b[0m Trial 23 finished with value: 93.20000457763672 and parameters: {'num_of_kernel_layer1': 15, 'num_of_kernel_layer2': 8, 'optimizer': 'Adam', 'lr': 0.00017956201024051934, 'num_epochs': 30, 'batch_size': 16}. Best is trial 12 with value: 93.85000610351562.\u001b[0m\n",
            "\u001b[32m[I 2020-12-11 16:37:39,261]\u001b[0m Trial 24 pruned. \u001b[0m\n",
            "\u001b[32m[I 2020-12-11 16:38:12,562]\u001b[0m Trial 25 pruned. \u001b[0m\n",
            "\u001b[32m[I 2020-12-11 16:46:31,888]\u001b[0m Trial 26 finished with value: 93.10000610351562 and parameters: {'num_of_kernel_layer1': 15, 'num_of_kernel_layer2': 8, 'optimizer': 'Adam', 'lr': 0.00017531744400274955, 'num_epochs': 30, 'batch_size': 16}. Best is trial 12 with value: 93.85000610351562.\u001b[0m\n",
            "\u001b[32m[I 2020-12-11 16:46:48,758]\u001b[0m Trial 27 pruned. \u001b[0m\n",
            "\u001b[32m[I 2020-12-11 16:47:34,320]\u001b[0m Trial 28 pruned. \u001b[0m\n",
            "\u001b[32m[I 2020-12-11 16:48:07,104]\u001b[0m Trial 29 pruned. \u001b[0m\n",
            "\u001b[32m[I 2020-12-11 16:56:36,155]\u001b[0m Trial 30 finished with value: 93.75000762939453 and parameters: {'num_of_kernel_layer1': 16, 'num_of_kernel_layer2': 8, 'optimizer': 'Adam', 'lr': 0.00014661280661840034, 'num_epochs': 30, 'batch_size': 16}. Best is trial 12 with value: 93.85000610351562.\u001b[0m\n",
            "\u001b[32m[I 2020-12-11 16:56:53,263]\u001b[0m Trial 31 pruned. \u001b[0m\n",
            "\u001b[32m[I 2020-12-11 16:57:08,976]\u001b[0m Trial 32 pruned. \u001b[0m\n",
            "\u001b[32m[I 2020-12-11 16:57:24,000]\u001b[0m Trial 33 pruned. \u001b[0m\n",
            "\u001b[32m[I 2020-12-11 16:57:38,718]\u001b[0m Trial 34 pruned. \u001b[0m\n",
            "\u001b[32m[I 2020-12-11 16:58:08,797]\u001b[0m Trial 35 pruned. \u001b[0m\n",
            "\u001b[32m[I 2020-12-11 16:58:24,601]\u001b[0m Trial 36 pruned. \u001b[0m\n",
            "\u001b[32m[I 2020-12-11 16:58:41,311]\u001b[0m Trial 37 pruned. \u001b[0m\n",
            "\u001b[32m[I 2020-12-11 16:58:57,919]\u001b[0m Trial 38 pruned. \u001b[0m\n",
            "\u001b[32m[I 2020-12-11 16:59:13,567]\u001b[0m Trial 39 pruned. \u001b[0m\n",
            "\u001b[32m[I 2020-12-11 16:59:30,374]\u001b[0m Trial 40 pruned. \u001b[0m\n",
            "\u001b[32m[I 2020-12-11 17:07:51,510]\u001b[0m Trial 41 finished with value: 93.65000915527344 and parameters: {'num_of_kernel_layer1': 15, 'num_of_kernel_layer2': 8, 'optimizer': 'Adam', 'lr': 0.00013148588623292237, 'num_epochs': 30, 'batch_size': 16}. Best is trial 12 with value: 93.85000610351562.\u001b[0m\n",
            "\u001b[32m[I 2020-12-11 17:16:10,601]\u001b[0m Trial 42 finished with value: 94.35000610351562 and parameters: {'num_of_kernel_layer1': 15, 'num_of_kernel_layer2': 8, 'optimizer': 'Adam', 'lr': 0.00021960477910777773, 'num_epochs': 30, 'batch_size': 16}. Best is trial 42 with value: 94.35000610351562.\u001b[0m\n",
            "\u001b[32m[I 2020-12-11 17:24:30,101]\u001b[0m Trial 43 finished with value: 91.6500015258789 and parameters: {'num_of_kernel_layer1': 15, 'num_of_kernel_layer2': 8, 'optimizer': 'Adam', 'lr': 0.00025234686402708016, 'num_epochs': 30, 'batch_size': 16}. Best is trial 42 with value: 94.35000610351562.\u001b[0m\n",
            "\u001b[32m[I 2020-12-11 17:25:03,975]\u001b[0m Trial 44 pruned. \u001b[0m\n",
            "\u001b[32m[I 2020-12-11 17:25:37,198]\u001b[0m Trial 45 pruned. \u001b[0m\n",
            "\u001b[32m[I 2020-12-11 17:25:53,335]\u001b[0m Trial 46 pruned. \u001b[0m\n",
            "\u001b[32m[I 2020-12-11 17:26:09,995]\u001b[0m Trial 47 pruned. \u001b[0m\n",
            "\u001b[32m[I 2020-12-11 17:26:26,268]\u001b[0m Trial 48 pruned. \u001b[0m\n",
            "\u001b[32m[I 2020-12-11 17:26:41,845]\u001b[0m Trial 49 pruned. \u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Study statistics: \n",
            "  Number of finished trials:  50\n",
            "  Number of pruned trials:  34\n",
            "  Number of complete trials:  16\n",
            "Best trial:\n",
            "  Value:  94.35000610351562\n",
            "  Params: \n",
            "    num_of_kernel_layer1: 15\n",
            "    num_of_kernel_layer2: 8\n",
            "    optimizer: Adam\n",
            "    lr: 0.00021960477910777773\n",
            "    num_epochs: 30\n",
            "    batch_size: 16\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}